---
title: "04 - Clean: dplyr"
author: Jeffrey W. Hollister
layout: post_page
---



In the last lesson we focused on some basic cleaning operations (subsetting, merging, modifying, and sumarizing) using base R.  I actually find myself still using these quite a bit.  That being said, I am slowly trying to make the switch to some of the packages that facilitate working with data frames, namely Hadley Wickham's `dplyr`. 

##Quick Links to Exercises and R code
- [Lesson 4 R Code](/gedr/rmd_posts/2015-01-14-04-Clean.R): All the code from this post in an R Script.
- [Exercise 1](#exercise-1): Subsetting the NLA data with `dplyr`
- [Exercise 2](#exercise-2): Using `dplyr` to modify and summarize the NLA.


##Lesson Goals
- Better understand data cleaning through use of `dplyr`
- Understand some of the differences between `dplyr` and base R.
- Be able to repeat what we know in base with `dplyr`
- Know what pipes are and why you might want to use them

##What is `dplyr`? 

The package `dplyr` is a fairly new (2014) package that tries to provide easy tools for the most common data manipulation tasks.  It is built to work directly with data frames.  The thinking behind it was largely inspired by the package `plyr` which has been in use for some time but suffered from being slow in some cases.  `dplyr` address this by porting much of the computation to C++.  An additional feature is the ability to work with data stored directly in an external database.  The benefits of doing this are that the data can be managed natively in a relational database, queries can be conducted on that database, and only the results of the query returned.  

This addresses a common problem with R in that all operations are conducted in memory and thus the amount of data you can work with is limited by available memory.  The database connections essentially remove that limitation in that you can have a database of many 100s GB, conduct queries on it directly and pull back just what you need for analysis in R.  There is a lot of great info on `dplyr`.  If you have an interest, i'd encourage you to look more.  The vignettes are particulary good.

- [`dplyr` GitHub repo](https://github.com/hadley/dplyr)
- [CRAN page: vignettes here](http://cran.rstudio.com/web/packages/dplyr/)

##Subsetting in `dplyr`
In base R we used a combination of indexing, indexing with vectors and `subset()` to select out columns and rows.  In `dplyr` this can be done with two functions, `select()` and `filter()`.  Before we start we need to make sure we've got everything installed and loaded.




{% highlight r %}
install.packages("dplyr")
library("dplyr")
{% endhighlight %}

Let's repeat what we did in the previous exercise with base R, but now with `dplyr`.  I think you will find it to be a bit more intuitive.


{% highlight r %}
#First, select some columns
dplyr_sel<-select(iris,Sepal.Length,Petal.Length,Species)
#That's it.  Select one or many columns
#Now select some, like before
dplyr_big_iris<-filter(iris, Petal.Length>=6)
head(dplyr_big_iris)
{% endhighlight %}



{% highlight text %}
##   Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
## 1          6.3         3.3          6.0         2.5 virginica
## 2          7.6         3.0          6.6         2.1 virginica
## 3          7.3         2.9          6.3         1.8 virginica
## 4          7.2         3.6          6.1         2.5 virginica
## 5          7.7         3.8          6.7         2.2 virginica
## 6          7.7         2.6          6.9         2.3 virginica
{% endhighlight %}



{% highlight r %}
#Or maybe we want just the virginica species
virginica_iris<-filter(iris,Species=="virginica")
head(virginica_iris)
{% endhighlight %}



{% highlight text %}
##   Sepal.Length Sepal.Width Petal.Length Petal.Width   Species
## 1          6.3         3.3          6.0         2.5 virginica
## 2          5.8         2.7          5.1         1.9 virginica
## 3          7.1         3.0          5.9         2.1 virginica
## 4          6.3         2.9          5.6         1.8 virginica
## 5          6.5         3.0          5.8         2.2 virginica
## 6          7.6         3.0          6.6         2.1 virginica
{% endhighlight %}

But what if I wanted to select and filter?  There are three ways to do this: use intermediate steps, nest functions, or pipes.  With the intermediate steps, you essentially create a temporary data frame and use that as input to the next function.  You can also nest functions (i.e. one function inside of another).  This is handy, but can be difficult to read if too many functions are nested.  The last option, pipes, are a fairly recent addition to R.  Pipes in the unix/linux world are not new and allow you to chain commands together where the output of one command is the input to the next.  This provides a more natural way to read the commands in that they are executed in the way you conceptualize it and make the interpretation of the code a bit easier.  Pipes in `dplyr` look like `%>%`.  Let's try all three with the same analysis.  Select out a subset of columns but for only a single species.


{% highlight r %}
#Intermediate data frames
#Select First: note the order of the output, neat too!
dplyr_big_iris_tmp1<-select(iris,Species,Sepal.Length,Petal.Length)
dplyr_big_iris_tmp<-filter(iris_tmp1,Petal.Length>=6)
{% endhighlight %}



{% highlight text %}
## Error in filter_(.data, .dots = lazyeval::lazy_dots(...)): object 'iris_tmp1' not found
{% endhighlight %}



{% highlight r %}
head(dplyr_big_iris_tmp)
{% endhighlight %}



{% highlight text %}
## Error in head(dplyr_big_iris_tmp): object 'dplyr_big_iris_tmp' not found
{% endhighlight %}



{% highlight r %}
#Nested function
dplyr_big_iris_nest<-filter(select(iris,Species,Sepal.Length,Petal.Length),Species=="virginica")
head(dplyr_big_iris_nest)
{% endhighlight %}



{% highlight text %}
##     Species Sepal.Length Petal.Length
## 1 virginica          6.3          6.0
## 2 virginica          5.8          5.1
## 3 virginica          7.1          5.9
## 4 virginica          6.3          5.6
## 5 virginica          6.5          5.8
## 6 virginica          7.6          6.6
{% endhighlight %}



{% highlight r %}
#Pipes
dplyr_big_iris_pipe<-select(iris,Species,Sepal.Length,Petal.Length) %>%
  filter(Species=="virginica")
head(dplyr_big_iris_pipe)
{% endhighlight %}



{% highlight text %}
##     Species Sepal.Length Petal.Length
## 1 virginica          6.3          6.0
## 2 virginica          5.8          5.1
## 3 virginica          7.1          5.9
## 4 virginica          6.3          5.6
## 5 virginica          6.5          5.8
## 6 virginica          7.6          6.6
{% endhighlight %}

##Exercise 1
We are simply going to re-do the same problem we did for the last lesson, but using `dplyr` commands instead.  Use the stickies when finished or if you have a problem.

1. First, from the  `nla_sites` data frame we want a new data frame that has only the following columns: SITE_ID, LON_DD, LAT_DD, STATE_NAME, WSA_ECO9, NUT_REG, NUTREG_NAME, LAKE_ORIGIN, and RT_NLA.  Name the new data frame `nla_sites_subset_dplyr`.
2. Using any of the methods mentioned above to combine multiple commands (I'd use pipes)
subset and filter the water quality data from `nla_wq`.  The columns we want for this are: SITE_ID, VISIT_NO, SITE_TYPE, TURB, NTL, PTL, CHLA, and SECMEAN. Call this `nla_wq_subset_dplyr`.  We need only the lakes with VISIT_NO equal to 1 and SITE_TYPE equal to "REF_Lake".   Name this, `nla_wq_subset_dplyr`.

##Merging Data
Joining data in `dplyr` is accomplished via the various `x_join()` commands (e.g., `inner_join`, `left_join`, `anti_join`, etc).  These are very SQL-esque so if you speak SQL (I am far from fluent!) then these will be pretty easy for you.  If not then they aren't immediately intutive.  For our purposes, `merge()` is more than adequate.  

##Modify and Summarize
One area where this package really shines is in modifying and summarizing.   We will do more here than we did with base, but first lets walk through one of the examples we did previously, aggregating.  We can do this with `group_by()` and `summarize()`.


{% highlight r %}
#Intermediate data frame
iris_grp<-group_by(iris,Species)
summarize(iris_grp,mean(Sepal.Length),
          mean(Sepal.Width),
          mean(Petal.Length),
          mean(Petal.Width))
{% endhighlight %}



{% highlight text %}
## Source: local data frame [3 x 5]
## 
##      Species mean(Sepal.Length) mean(Sepal.Width) mean(Petal.Length)
## 1     setosa              5.006             3.428              1.462
## 2 versicolor              5.936             2.770              4.260
## 3  virginica              6.588             2.974              5.552
## Variables not shown: mean(Petal.Width) (dbl)
{% endhighlight %}



{% highlight r %}
#Chained with Pipes
group_by(iris,Species)%>%
  summarize(mean(Sepal.Length),
            mean(Sepal.Width),
            mean(Petal.Length),
            mean(Petal.Width))
{% endhighlight %}



{% highlight text %}
## Source: local data frame [3 x 5]
## 
##      Species mean(Sepal.Length) mean(Sepal.Width) mean(Petal.Length)
## 1     setosa              5.006             3.428              1.462
## 2 versicolor              5.936             2.770              4.260
## 3  virginica              6.588             2.974              5.552
## Variables not shown: mean(Petal.Width) (dbl)
{% endhighlight %}

It is certainly true that we can do it with less code using `aggregate()`, but what we buy with the extra code is a ton of flexibility.  

There are many other functions in `dplyr` that are useful.  Much of what they do, can certainly be accomplished with base R, but not quite as intuitively.  Let's run through some examples with `arrange()`, `slice()`,  and `mutate()`.

First `arrange()` will re-order a data frame based on the values of a columns.  It will take multiple columns and can be in descending or ascending order. I think `iris` is getting a bit tired, let's try a different stock data frame this time:  `mtcars`.  If you are interested you can try `data()` to see what is available.


{% highlight r %}
head(mtcars)
{% endhighlight %}



{% highlight text %}
##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1
{% endhighlight %}



{% highlight r %}
#ascending order is default
head(arrange(mtcars,mpg))
{% endhighlight %}



{% highlight text %}
##    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## 1 10.4   8  472 205 2.93 5.250 17.98  0  0    3    4
## 2 10.4   8  460 215 3.00 5.424 17.82  0  0    3    4
## 3 13.3   8  350 245 3.73 3.840 15.41  0  0    3    4
## 4 14.3   8  360 245 3.21 3.570 15.84  0  0    3    4
## 5 14.7   8  440 230 3.23 5.345 17.42  0  0    3    4
## 6 15.0   8  301 335 3.54 3.570 14.60  0  1    5    8
{% endhighlight %}



{% highlight r %}
#descending
head(arrange(mtcars,desc(mpg)))
{% endhighlight %}



{% highlight text %}
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb
## 1 33.9   4  71.1  65 4.22 1.835 19.90  1  1    4    1
## 2 32.4   4  78.7  66 4.08 2.200 19.47  1  1    4    1
## 3 30.4   4  75.7  52 4.93 1.615 18.52  1  1    4    2
## 4 30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2
## 5 27.3   4  79.0  66 4.08 1.935 18.90  1  1    4    1
## 6 26.0   4 120.3  91 4.43 2.140 16.70  0  1    5    2
{% endhighlight %}



{% highlight r %}
#multiple columns: most cyl with best mpg at top
head(arrange(mtcars,desc(cyl),desc(mpg)))
{% endhighlight %}



{% highlight text %}
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb
## 1 19.2   8 400.0 175 3.08 3.845 17.05  0  0    3    2
## 2 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
## 3 17.3   8 275.8 180 3.07 3.730 17.60  0  0    3    3
## 4 16.4   8 275.8 180 3.07 4.070 17.40  0  0    3    3
## 5 15.8   8 351.0 264 4.22 3.170 14.50  0  1    5    4
## 6 15.5   8 318.0 150 2.76 3.520 16.87  0  0    3    2
{% endhighlight %}

Now `slice()` which accomplishes what we did with the numeric indices before.  Remembering back to that, we'd could grab rows of data frame with something like `x[1:3,]`.  


{% highlight r %}
#grab rows 3 through 10
slice(mtcars,3:10)
{% endhighlight %}



{% highlight text %}
##    mpg cyl  disp  hp drat    wt  qsec vs am gear carb
## 1 22.8   4 108.0  93 3.85 2.320 18.61  1  1    4    1
## 2 21.4   6 258.0 110 3.08 3.215 19.44  1  0    3    1
## 3 18.7   8 360.0 175 3.15 3.440 17.02  0  0    3    2
## 4 18.1   6 225.0 105 2.76 3.460 20.22  1  0    3    1
## 5 14.3   8 360.0 245 3.21 3.570 15.84  0  0    3    4
## 6 24.4   4 146.7  62 3.69 3.190 20.00  1  0    4    2
## 7 22.8   4 140.8  95 3.92 3.150 22.90  1  0    4    2
## 8 19.2   6 167.6 123 3.92 3.440 18.30  1  0    4    4
{% endhighlight %}

Lastly, `mutate()` allows us to add new columns based on expressions applied to existing columns


{% highlight r %}
head(mutate(mtcars_dplyr,kml=mpg*0.425))
{% endhighlight %}



{% highlight text %}
## Error in mutate_(.data, .dots = lazyeval::lazy_dots(...)): object 'mtcars_dplyr' not found
{% endhighlight %}

We now have quite a few tools that we can use to clean and manipulate in R.  We have barely touched what both base R and `dplyr` are capable of accomplishing, but hopefully you now have some basics to build on.  I personally think the database connection in `dplyr` are going to prove very useful.

Let's practice some of these last functions with our NLA data.

##Exercise 2
Lastly, lets add a new section to our script to recalculate the nla water quality means but using `dplyr`. 

1. Use `nla_data` that we created in the previous lesson.
2. Add some lines to your script to calculate the mean by LAKE_ORIGIN, for TURB, NTL, PTL,CHLA, and SECMEAN (hint: columns 4 through 8). Save to a data frame named origin_mean_wq_dplyr.
3. Repeat the same analysis but for the `WSA_ECO9` ecoregions.  Save this to a data frame named `ecoregion_mean_wq_dplyr`.
4. It might be interesting to compare the grouped means to the means of each value for the entire dataset.  Using `summarize()`, calculate the mean wq for all lakes (hint: no groups!).  Save this as `nla_mean_wq_dplyr`.

