---
title: "04 - Clean: dplyr"
author: Jeffrey W. Hollister
layout: post_page
---
In the last lesson we focused on some basic cleaning operations (subsetting, merging, modifying, and sumarizing) using base R.  I actually find myself still using these quite a bit.  That being said, I am slowly trying to make the switch to some of the packages that facilitate working with data frames, namely Hadley Wickham's `dplyr`. 

##Quick Links to Exercises and R code
- [Lesson 4 R Code](/gedr/rmd_posts/2015-01-14-04-Clean.R): All the code from this post in an R Script.
- [Exercise 1](#exercise-1): Subsetting the NLA data with `dplyr`
- [Exercise 2](#exercise-2): Using `dplyr` to modify and summarize the NLA.


##Lesson Goals
- Better understand data cleaning through use of `dplyr`
- Understand some of the differences between `dplyr` and base R.
- Be able to repeat what we know in base with `dplyr`
- Know what pipes are and why you might want to use them

##What is `dplyr`? 

The package `dplyr` is a fairly new (2014) package that tries to provide easy tools for the most common data manipulation tasks.  It is built to work directly with data frames.  The thinking behind it was largely inspired by the package `plyr` which has been in use for some time but suffered from being slow in some cases.  `dplyr` address this by porting much of the computation to C++.  An additional feature is the ability to work with data stored directly in an external database.  The benefits of doing this are that the data can be managed natively in a relational database, queries can be conducted on that database, and only the results of the query returned.  

This addresses a common problem with R in that all operations are conducted in memory and thus the amount of data you can work with is limited by available memory.  The database connections essentially remove that limitation in that you can have a database of many 100s GB, conduct queries on it directly and pull back just what you need for analysis in R.  There is a lot of great info on `dplyr`.  If you have an interest, i'd encourage you to look more.  The vignettes are particulary good.

- [`dplyr` GitHub repo](https://github.com/hadley/dplyr)
- [CRAN page: vignettes here](http://cran.rstudio.com/web/packages/dplyr/)

##Subsetting in `dplyr`
In base R we used a combination of indexing, indexing with vectors and `subset()` to select out columns and rows.  In `dplyr` this can be done with two functions, `select()` and `filter()`.  Before we start we need to make sure we've got everything installed and loaded.

```{r setup_dplyr}
install.packages("dplyr")
library("dplyr")
```

Let's repeat what we did in the previous exercise with base R, but now with `dplyr`.  I think you will find it to be a bit more intuitive.

```{r more_data_frame_index}
#First, select some columns
dplyr_sel<-select(iris,Sepal.Length,Petal.Length,Species)
#That's it.  Select one or many columns
#Now select some, like before
dplyr_big_iris<-filter(iris, Petal.Length>=6)
head(dplyr_big_iris)
#Or maybe we want just the sepal widths of the virginica species
virginica_iris<-filter(iris,Species=="virginica")
head(virginica_iris)
```

But what if I wanted to select and filter?  There are three ways to do this: use intermediate steps, nest functions, or pipes.  With the intermediate steps, you essentially create a temporary data frame and use that as input to the next function.  You can also nest functions (i.e. one function inside of another).  This is handy, but can be difficult to read if too many functions are nested.  The last option, pipes, are a fairly recent addition to R.  Pipes in the unix/linux world are not new and allow you to chain commands together where the output of one command is the input to the next.  This provides a more natural way to read the commands in that they are executed in the way you conceptualize it and make the interpretation of the code a bit easier.  Pipes in `dplyr` look like `%>%`.  Let's try all three with the same analysis.  Select out a subset of columns but for only a single species.

```{r combine_commands}
#Intermediate data frames
#Select First: note the order of the output, neat too!
dplyr_big_iris_tmp1<-select(iris,Species,Sepal.Length,Petal.Length)
dplyr_big_iris_tmp<-filter(iris_tmp1,Petal.Length>=6)
head(dplyr_big_iris_tmp)
#Nested function
dplyr_big_iris_nest<-filter(select(iris,Species,Sepal.Length,Petal.Length),Species=="virginica")
head(dplyr_big_iris_nest)
#Pipes
dplyr_big_iris_pipe<-select(iris,Species,Sepal.Length,Petal.Length) %>%
  filter(Species=="virginica")
head(dplyr_big_iris_pipe)
```

##Exercise 1
We are simply going to re-do the same problem we did for the last lesson, but using `dplyr` commands instead.  Use the stickies when finished or if you have a problem.

1. First, from the  `nla_sites` data frame we want a new data frame that has only the following columns: SITE_ID, LON_DD, LAT_DD, STATE_NAME, WSA_ECO9, NUT_REG, NUTREG_NAME, LAKE_ORIGIN, and RT_NLA.  Name the new data frame `nla_sites_subset_dplyr`.
2. Using any of the methods mentioned above to combine multiple commands (I'd use pipes)
subset and filter the water quality data from `nla_wq`.  The columns we want for this are: SITE_ID, VISIT_NO, SITE_TYPE, TURB, NTL, PTL, CHLA, and SECMEAN. Call this `nla_wq_subset_dplyr`.  We need only the lakes with VISIT_NO equal to 1 and SITE_TYPE equal to "REF_Lake".   Name this, `nla_wq_subset_dplyr`.

##Merging Data
Joining data in `dplyr` is accomplished via the various `x_join()` commands (e.g., `inner_join`, `left_join`, `anti_join`, etc).  These are very SQL-esque so if you speak SQL (I am far from fluent!) then these will be pretty easy for you.  If not then they aren't immediately intutive.  For our purposes, `merge()` is more than adequate.  

##Modify and Summarize
One area where this package really shines is in modifying and summarizing.   We will do more here than we did with base, but first lets walk through one of the examples we did previously, aggregating.  We can do this with `group_by()` and `summarize()`.

```{r aggregate_examp}
#Intermediate data frame
iris_grp<-group_by(iris,Species)
summarize(iris_grp,mean(Sepal.Length),
          mean(Sepal.Width),
          mean(Petal.Length),
          mean(Petal.Width))
#Chained with Pipes
group_by(iris,Species)%>%
  summarize(mean(Sepal.Length),
            mean(Sepal.Width),
            mean(Petal.Length),
            mean(Petal.Width))
```

It is certainly true that we can do it with less code using `aggregate()`, but what we buy with the extra code is a ton of flexibility.  

There are many other functions in `dplyr` that are useful.  Much of what they do, can certainly be accomplished with base R, but not in as quite an intuitive fashion.  Let's run through some examples with `aggregate()`, `slice()`, `mutate()`, and `arrange()`.

##Exercise 2


